model:
  chatmodel:
    type: 
      text-to-text:
        api_type: "Groq"
        model: "llama-3.3-70b-versatile" #llama-3.1-8b-instant
        temperature: 0.7
        max_tokens: 1024